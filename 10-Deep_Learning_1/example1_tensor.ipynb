{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Tutorial - example1\n",
    "MILA, November 2017 created by Sandeep Subramanian, <br>\n",
    "modified by Sam,Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Getting Started\n",
    "---------------\n",
    "\n",
    "Tensors are similar to NumPyâ€™s ndarrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to the torch tensor library\n",
    "### Torch's numpy equivalent with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a random tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.6769e+03, 3.0948e-41, 5.7453e-44],\n",
       "        [0.0000e+00,        nan, 0.0000e+00],\n",
       "        [1.3733e-14, 6.4076e+07, 2.0706e-19],\n",
       "        [7.3909e+22, 2.4176e-12, 1.1625e+33],\n",
       "        [8.9605e-01, 1.1632e+33, 5.6003e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0712,  0.7814, -0.7625],\n",
       "        [ 0.0949,  0.3324,  0.5096],\n",
       "        [-0.3215, -0.8707,  0.0575],\n",
       "        [-0.5614, -0.3230,  0.3477],\n",
       "        [ 0.3403, -0.0070, -0.7052]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(5, 3).uniform_(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get it's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Types\n",
    "source: http://pytorch.org/docs/master/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Data type |CPU Tensor| \n",
    "|----------|------|\n",
    "|32-bit floating point\t\t|torch.FloatTensor\t|\n",
    "|64-bit floating point\t\t|torch.DoubleTensor\t|\n",
    "|16-bit floating point\t\t|torch.HalfTensor\t|\n",
    "|8-bit integer (unsigned)\t|torch.ByteTensor\t| \n",
    "|8-bit integer (signed)\t\t|torch.CharTensor\t|\n",
    "|16-bit integer (signed)\t|torch.ShortTensor\t|\n",
    "|32-bit integer (signed)\t|torch.IntTensor\t|\n",
    "|64-bit integer (signed)\t|torch.LongTensor\t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation from lists & numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "z_list = [[1, 3], [2, 9]]\n",
    "z_tensor = torch.LongTensor(z_list)\n",
    "\n",
    "print(z_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Data type inferred from numpy\n",
    "print(torch.from_numpy(np.random.rand(5, 3)).type())\n",
    "print(torch.from_numpy(np.random.rand(5, 3).astype(np.float32)).type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7605, -0.2435, -0.3830],\n",
      "        [ 0.6698,  0.1130, -0.2465],\n",
      "        [ 0.9572, -1.3255,  0.0036],\n",
      "        [ 0.8017, -0.0366,  0.3109],\n",
      "        [-0.0631,  0.8614, -0.3993]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(5, 3).uniform_(-1, 1)\n",
    "y = x * torch.randn(5, 3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14.1449,  0.7642,  1.8585],\n",
      "        [ 1.2187, -0.9488, -1.4919],\n",
      "        [ 1.6364, -0.5949, -0.0046],\n",
      "        [-0.3041, -0.0480,  0.7258],\n",
      "        [-0.8817,  2.4246, -2.3724]])\n"
     ]
    }
   ],
   "source": [
    "y = x / torch.sqrt(torch.randn(5, 3) ** 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "tensor([[-0.7309, -1.4779, -0.9464],\n",
      "        [ 2.3813,  0.8688,  1.0954],\n",
      "        [ 2.2766,  1.0436,  1.6930],\n",
      "        [ 0.1567,  0.6982,  1.6095],\n",
      "        [-0.8439,  0.5500, -0.7834]])\n"
     ]
    }
   ],
   "source": [
    "print (x.size())\n",
    "y = x + torch.randn(5, 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 15])\n",
      "torch.Size([50, 15])\n",
      "torch.Size([50, 1, 15])\n",
      "torch.Size([50, 15])\n",
      "\n",
      "torch.Size([10, 5, 15])\n",
      "torch.Size([5, 15, 10])\n",
      "torch.Size([10, 15, 5])\n",
      "torch.Size([10, 15, 5])\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(5, 10, 15)\n",
    "print(y.size())\n",
    "print(y.view(-1, 15).size())  # Same as doing y.view(50, 15)\n",
    "print(y.view(-1, 15).unsqueeze(1).size()) # Adds a dimension at index 1.\n",
    "print(y.view(-1, 15).unsqueeze(1).squeeze().size())\n",
    "# If input is of shape: (Ax1xBxCx1xD)(Ax1xBxCx1xD) then the out Tensor will be of shape: (AxBxCxD)(AxBxCxD)\n",
    "print()\n",
    "print(y.transpose(0, 1).size())\n",
    "print(y.transpose(1, 2).size())\n",
    "print(y.transpose(0, 1).transpose(1, 2).size())\n",
    "print(y.permute(1, 2, 0).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100, 15])\n",
      "torch.Size([50, 100, 15])\n"
     ]
    }
   ],
   "source": [
    "print(y.view(-1, 15).unsqueeze(1).expand(50, 100, 15).size())\n",
    "print(y.view(-1, 15).unsqueeze(1).expand_as(torch.randn(50, 100, 15)).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.9537, 1.2066, 1.7382],\n",
      "        [1.9578, 0.4452, 0.6718],\n",
      "        [1.5760, 0.3430, 0.9924],\n",
      "        [0.4027, 0.9442, 1.8555],\n",
      "        [0.2741, 1.6680, 0.3346]], device='cuda:0')\n",
      "tensor([[1.9537, 1.2066, 1.7382],\n",
      "        [1.9578, 0.4452, 0.6718],\n",
      "        [1.5760, 0.3430, 0.9924],\n",
      "        [0.4027, 0.9442, 1.8555],\n",
      "        [0.2741, 1.6680, 0.3346]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move tensors on the CPU -> GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7782,  0.3327, -0.3481],\n",
      "        [-0.0272, -0.8448, -0.7944],\n",
      "        [-0.6959,  0.5204,  0.2608],\n",
      "        [-0.2203,  0.0886,  0.7475],\n",
      "        [ 0.3075, -0.3202,  0.4930]])\n",
      "tensor([[-0.7782,  0.3327, -0.3481],\n",
      "        [-0.0272, -0.8448, -0.7944],\n",
      "        [-0.6959,  0.5204,  0.2608],\n",
      "        [-0.2203,  0.0886,  0.7475],\n",
      "        [ 0.3075, -0.3202,  0.4930]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(5, 3).uniform_(-1, 1)\n",
    "print(x)\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda(device=0)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and torch.Tensor comparison\n",
    "### Type\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                  </th><th>PyTorch                                 </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>np.ndarray</code></td><td><code>torch.Tensor</code>               </td></tr>\n",
    "<tr><td><code>np.float32</code></td><td><code>torch.float32; torch.float</code> </td></tr>\n",
    "<tr><td><code>np.float64</code></td><td><code>torch.float64; torch.double</code></td></tr>\n",
    "<tr><td><code>np.float16</code></td><td><code>torch.float16; torch.half</code>  </td></tr>\n",
    "<tr><td><code>np.int8</code>   </td><td><code>torch.int8</code>                 </td></tr>\n",
    "<tr><td><code>np.uint8</code>  </td><td><code>torch.uint8</code>                </td></tr>\n",
    "<tr><td><code>np.int16</code>  </td><td><code>torch.int16; torch.short</code>   </td></tr>\n",
    "<tr><td><code>np.int32</code>  </td><td><code>torch.int32; torch.int</code>     </td></tr>\n",
    "<tr><td><code>np.int64</code>  </td><td><code>torch.int64; torch.long</code>    </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical ranges\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                            </th><th>PyTorch                             </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>np.arange(10)</code>       </td><td><code>torch.arange(10)</code>       </td></tr>\n",
    "<tr><td><code>np.arange(2, 3, 0.1)</code></td><td><code>torch.arange(2, 3, 0.1)</code></td></tr>\n",
    "<tr><td><code>np.linspace</code>         </td><td><code>torch.linspace</code>         </td></tr>\n",
    "<tr><td><code>np.logspace</code>         </td><td><code>torch.logspace</code>         </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attributes\n",
    "\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                 </th><th>PyTorch                  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>x.shape</code>  </td><td><code>x.shape</code>     </td></tr>\n",
    "<tr><td><code>x.strides</code></td><td><code>x.stride()</code>  </td></tr>\n",
    "<tr><td><code>x.ndim</code>   </td><td><code>x.dim()</code>     </td></tr>\n",
    "<tr><td><code>x.data</code>   </td><td><code>x.data</code>      </td></tr>\n",
    "<tr><td><code>x.size</code>   </td><td><code>x.nelement()</code></td></tr>\n",
    "<tr><td><code>x.dtype</code>  </td><td><code>x.dtype</code>     </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation\n",
    "<table align='left'>\n",
    "<thead>\n",
    "<tr><th>Numpy                   </th><th>PyTorch                                    </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td><code>x.min</code>      </td><td><code>x.min</code>                         </td></tr>\n",
    "<tr><td><code>x.argmin</code>   </td><td><code>x.argmin</code>                      </td></tr>\n",
    "<tr><td><code>x.max</code>      </td><td><code>x.max</code>                         </td></tr>\n",
    "<tr><td><code>x.argmax</code>   </td><td><code>x.argmax</code>                      </td></tr>\n",
    "<tr><td><code>x.clip</code>     </td><td><code>x.clamp</code>                       </td></tr>\n",
    "<tr><td><code>x.round</code>    </td><td><code>x.round</code>                       </td></tr>\n",
    "<tr><td><code>np.floor(x)</code></td><td><code>torch.floor(x); x.floor()</code>     </td></tr>\n",
    "<tr><td><code>np.ceil(x)</code> </td><td><code>torch.ceil(x); x.ceil()</code>       </td></tr>\n",
    "<tr><td><code>x.trace</code>    </td><td><code>x.trace</code>                       </td></tr>\n",
    "<tr><td><code>x.sum</code>      </td><td><code>x.sum</code>                         </td></tr>\n",
    "<tr><td><code>x.cumsum</code>   </td><td><code>x.cumsum</code>                      </td></tr>\n",
    "<tr><td><code>x.mean</code>     </td><td><code>x.mean</code>                        </td></tr>\n",
    "<tr><td><code>x.std</code>      </td><td><code>x.std</code>                         </td></tr>\n",
    "<tr><td><code>x.prod</code>     </td><td><code>x.prod</code>                        </td></tr>\n",
    "<tr><td><code>x.cumprod</code>  </td><td><code>x.cumprod</code>                     </td></tr>\n",
    "<tr><td><code>x.all</code>      </td><td><code>(x == 1).sum() == x.nelement()</code></td></tr>\n",
    "<tr><td><code>x.any</code>      </td><td><code>(x == 1).sum() > 0</code>            </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
